# Plan de Suppression de l'Agent Cadrage

## üéØ Objectif

Supprimer l'Agent Cadrage du workflow MAESTRO pour simplifier l'architecture et √©liminer l'ambigu√Øt√© sur le scope des User Stories.

## üìä √âtat Actuel

- ‚úÖ **Table `cadrages`** : 0 enregistrements (aucune donn√©e √† migrer)
- ‚úÖ **Workflows n8n** : Agent Cadrage existe mais pas utilis√© en production
- ‚ö†Ô∏è **Table `user_stories`** : Contient une colonne `cadrage_id` (nullable)
- ‚ö†Ô∏è **Table `projects`** : Contient `project_cadrage` (JSONB)

## üìã Plan d'Action

### 1Ô∏è‚É£ Migration Base de Donn√©es

#### A. Supprimer la colonne `cadrage_id` de `user_stories`

```sql
-- V√©rifier s'il y a des valeurs non-null (il ne devrait pas y en avoir)
SELECT COUNT(*) FROM maestro.user_stories WHERE cadrage_id IS NOT NULL;

-- Supprimer la colonne
ALTER TABLE maestro.user_stories DROP COLUMN IF EXISTS cadrage_id;
```

#### B. Renommer/Simplifier la table `cadrages` ‚Üí `cadrage_proposals`

**Nouvelle philosophie** : Les cadrages deviennent des **propositions** qu'on peut appliquer au projet, pas des entit√©s interm√©diaires dans le workflow.

```sql
-- Option 1: Supprimer compl√®tement (recommand√©)
DROP TABLE IF EXISTS maestro.cadrages CASCADE;

-- Option 2: Garder pour l'historique mais renommer
ALTER TABLE maestro.cadrages RENAME TO cadrage_proposals_archive;
ALTER TABLE maestro.cadrage_proposals_archive
  ADD COLUMN archived_at TIMESTAMP DEFAULT NOW();
```

#### C. Nettoyer `project_cadrage` dans `projects`

Le champ `project_cadrage` reste mais change de r√¥le :
- **Avant** : Rempli par Agent Cadrage via workflow
- **Apr√®s** : Rempli manuellement ou via import, utilis√© uniquement pour contexte technique

```sql
-- Optionnel: R√©initialiser project_cadrage pour repartir de z√©ro
UPDATE maestro.projects
SET project_cadrage = NULL,
    project_cadrage_version = NULL,
    project_cadrage_updated_at = NULL
WHERE project_cadrage IS NOT NULL;
```

### 2Ô∏è‚É£ Modification des Workflows n8n

#### A. Supprimer `Agent Cadrage.json`

```bash
# Fichier √† supprimer
rm n8n_data/Agent\ Cadrage.json

# Ou via l'interface n8n: d√©sactiver puis supprimer le workflow
```

#### B. Modifier `Agent Orchestrator.json`

**Changements** :

1. **Supprimer la r√©f√©rence √† CADRAGE dans le parsing** :

```javascript
// AVANT (ligne ~90)
needs_cadrage: agentsNeeded.includes('CADRAGE'),
needs_us: agentsNeeded.includes('US'),
// ...
cadrage_id: null,

// APR√àS
needs_us: agentsNeeded.includes('US'),
needs_dev: agentsNeeded.includes('DEV'),
// ...
// Supprimer cadrage_id compl√®tement
```

2. **Supprimer le n≈ìud "Call Agent Cadrage"** du workflow

3. **Reconnecter directement PM ‚Üí US** :

```
Agent PM (Analysis)
    ‚Üì
Agent US Generator (si needs_us)
    ‚Üì
Agent DEV (si needs_dev)
```

#### C. Simplifier `Agent US Generator.json`

**Fichier complet modifi√©** :

```json
{
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "user-stories",
        "responseMode": "responseNode"
      },
      "type": "n8n-nodes-base.webhook",
      "position": [-640, 240],
      "id": "webhook-us",
      "name": "Webhook User Stories"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "field1",
              "name": "analysis_id",
              "value": "={{ $json.body.analysis_id }}",
              "type": "string"
            },
            {
              "id": "field2",
              "name": "request_id",
              "value": "={{ $json.body.request_id }}",
              "type": "string"
            },
            {
              "id": "field3",
              "name": "project_id",
              "value": "={{ $json.body.project_id }}",
              "type": "string"
            },
            {
              "id": "field4",
              "name": "request_text",
              "value": "={{ $json.body.request_text }}",
              "type": "string"
            },
            {
              "id": "field5",
              "name": "complexity",
              "value": "={{ $json.body.complexity }}",
              "type": "string"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.set",
      "position": [-440, 240],
      "id": "keep-input-us",
      "name": "Keep Input Data"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT project_cadrage FROM maestro.projects WHERE id = $1::uuid",
        "options": {
          "queryReplacement": "={{ $('Keep Input Data').item.json.project_id }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "position": [-240, 240],
      "id": "fetch-project-stack",
      "name": "Fetch Project Stack"
    },
    {
      "parameters": {
        "jsCode": "// Pr√©parer les donn√©es pour Gemini\nconst inputData = $input.first().json;\nconst projectData = $('Fetch Project Stack').first().json;\n\n// Extraire UNIQUEMENT la stack technique\nlet stackTechnique = 'Non sp√©cifi√©';\n\nif (projectData?.project_cadrage?.architecture?.stack_technique) {\n  stackTechnique = projectData.project_cadrage.architecture.stack_technique;\n}\n\nreturn [{\n  json: {\n    request_text: inputData.request_text,\n    complexity: inputData.complexity,\n    stack_technique: stackTechnique,\n    analysis_id: inputData.analysis_id,\n    project_id: inputData.project_id\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "position": [-40, 240],
      "id": "prepare-context",
      "name": "Prepare Context"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key={{ $env.GEMINI_API_KEY }}",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ {\n  \"contents\": [{\n    \"parts\": [{\n      \"text\": `Tu es le Product Owner de MAESTRO, expert en r√©daction de User Stories Agile.\n\n=== DEMANDE SP√âCIFIQUE √Ä IMPL√âMENTER ===\n${$json.request_text}\n\nComplexit√© estim√©e: ${$json.complexity}\n\n=== STACK TECHNIQUE DU PROJET (contraintes uniquement) ===\n${$json.stack_technique}\n\n‚ö†Ô∏è R√àGLES STRICTES :\n1. G√©n√®re des User Stories UNIQUEMENT pour la demande ci-dessus\n2. N'ajoute AUCUNE fonctionnalit√© qui n'est pas explicitement demand√©e\n3. La stack technique sert UNIQUEMENT √† conna√Ætre les contraintes techniques (langage, framework, base de donn√©es)\n4. Ne g√©n√®re PAS de fonctionnalit√©s annexes (auth, admin, monitoring, etc.) sauf si explicitement demand√©es\n\nMission :\n1. D√©composer LA DEMANDE en User Stories atomiques (1-5 jours max chacune)\n2. Format : En tant que [persona]... Je veux [action]... Afin de [b√©n√©fice]...\n3. Crit√®res d'acceptation en format Gherkin (Given/When/Then)\n4. Estimation en story points (Fibonacci: 1,2,3,5,8,13)\n5. Priorisation MoSCoW (MUST/SHOULD/COULD/WONT)\n6. Identifier les d√©pendances entre stories\n\nExemple : Si la demande est \"Cr√©er une page de CGV\" :\n‚úÖ US-001: Cr√©er la structure HTML de la page CGV\n‚úÖ US-002: R√©diger le contenu l√©gal des CGV\n‚úÖ US-003: Ajouter le versioning des CGV\n‚ùå PAS de stories sur l'authentification, la gestion utilisateurs, etc.\n\nR√©ponds UNIQUEMENT en JSON avec cette structure exacte :\n{\n  \"epic\": {\n    \"title\": \"Titre epic bas√© sur la demande\",\n    \"goal\": \"Objectif business mesurable\"\n  },\n  \"stories\": [\n    {\n      \"id\": \"US-001\",\n      \"title\": \"Titre court et explicite\",\n      \"as_a\": \"type utilisateur/persona\",\n      \"i_want\": \"action/fonctionnalit√© souhait√©e\",\n      \"so_that\": \"b√©n√©fice/valeur attendue\",\n      \"acceptance_criteria\": [\n        \"GIVEN [contexte] WHEN [action] THEN [r√©sultat]\"\n      ],\n      \"story_points\": 3,\n      \"priority\": \"MUST\",\n      \"dependencies\": [],\n      \"technical_notes\": \"Notes techniques\",\n      \"test_scenarios\": [\"Sc√©nario 1\"]\n    }\n  ],\n  \"metrics\": {\n    \"total_points\": 0,\n    \"must_have_points\": 0,\n    \"should_have_points\": 0,\n    \"could_have_points\": 0\n  }\n}`\n    }]\n  }],\n  \"generationConfig\": {\n    \"temperature\": 0.7,\n    \"topK\": 40,\n    \"topP\": 0.95,\n    \"maxOutputTokens\": 4096,\n    \"responseMimeType\": \"application/json\"\n  }\n} }}",
        "options": {
          "timeout": 90000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "position": [160, 240],
      "id": "gemini-us",
      "name": "Gemini US Generation"
    },
    {
      "parameters": {
        "jsCode": "// Parser la r√©ponse Gemini\nconst geminiResponse = $input.first().json;\nconst contextData = $('Prepare Context').first().json;\n\nconsole.log('=== AGENT USER STORIES ===');\nconsole.log('Analysis ID:', contextData.analysis_id);\n\nlet userStories = {};\ntry {\n  const textContent = geminiResponse.candidates[0].content.parts[0].text;\n  userStories = JSON.parse(textContent);\n  console.log('‚úì ' + (userStories.stories?.length || 0) + ' User Stories g√©n√©r√©es');\n  console.log('Total points:', userStories.metrics?.total_points || 0);\n} catch(e) {\n  console.error('‚úó Erreur parsing Gemini:', e.message);\n  userStories = {\n    epic: { title: 'Erreur de parsing', goal: 'N/A' },\n    stories: [],\n    metrics: { total_points: 0 }\n  };\n}\n\n// Pr√©parer un item par story pour insertion\nconst stories = userStories.stories || [];\nconst results = stories.map(story => ({\n  project_id: contextData.project_id,\n  analysis_id: contextData.analysis_id,\n  story_id: story.id,\n  title: story.title,\n  as_a: story.as_a,\n  i_want: story.i_want,\n  so_that: story.so_that,\n  priority: story.priority || 'SHOULD',\n  story_points: story.story_points || 0,\n  acceptance_criteria: JSON.stringify(story.acceptance_criteria || []),\n  test_scenarios: JSON.stringify(story.test_scenarios || []),\n  technical_notes: story.technical_notes || '',\n  dependencies: JSON.stringify(story.dependencies || [])\n}));\n\nconsole.log('Prepared ' + results.length + ' stories for DB insertion');\n\nreturn results.map(r => ({ json: r }));"
      },
      "type": "n8n-nodes-base.code",
      "position": [360, 240],
      "id": "prepare-us-data",
      "name": "Parse & Prepare Stories"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO maestro.user_stories (\n  project_id,\n  analysis_id,\n  story_id,\n  title,\n  as_a,\n  i_want,\n  so_that,\n  priority,\n  story_points,\n  acceptance_criteria,\n  test_scenarios,\n  technical_notes,\n  dependencies,\n  status\n) VALUES (\n  $1::uuid,\n  $2::uuid,\n  $3,\n  $4,\n  $5,\n  $6,\n  $7,\n  $8,\n  $9,\n  $10::jsonb,\n  $11::jsonb,\n  $12,\n  $13::jsonb,\n  'PENDING'\n) RETURNING id, story_id;",
        "options": {
          "queryReplacement": "={{ [\n  $json.project_id,\n  $json.analysis_id,\n  $json.story_id,\n  $json.title,\n  $json.as_a,\n  $json.i_want,\n  $json.so_that,\n  $json.priority,\n  $json.story_points,\n  $json.acceptance_criteria,\n  $json.test_scenarios,\n  $json.technical_notes,\n  $json.dependencies\n] }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "position": [560, 240],
      "id": "save-us",
      "name": "Save User Story"
    },
    {
      "parameters": {
        "jsCode": "// Agr√©ger les r√©sultats\nconst insertions = $input.all();\nconst totalStories = insertions.length;\n\nconsole.log('‚úì Successfully inserted ' + totalStories + ' user stories');\n\nreturn [{\n  json: {\n    status: 'success',\n    agent: 'US',\n    message: totalStories + ' User Stories cr√©√©es',\n    total_stories: totalStories,\n    story_ids: insertions.map(i => i.json.story_id)\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "position": [760, 240],
      "id": "aggregate-results",
      "name": "Aggregate Results"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify($json, null, 2) }}"
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [960, 240],
      "id": "respond-us",
      "name": "Respond Success"
    }
  ],
  "connections": {
    "Webhook User Stories": {
      "main": [[{"node": "Keep Input Data", "type": "main", "index": 0}]]
    },
    "Keep Input Data": {
      "main": [[{"node": "Fetch Project Stack", "type": "main", "index": 0}]]
    },
    "Fetch Project Stack": {
      "main": [[{"node": "Prepare Context", "type": "main", "index": 0}]]
    },
    "Prepare Context": {
      "main": [[{"node": "Gemini US Generation", "type": "main", "index": 0}]]
    },
    "Gemini US Generation": {
      "main": [[{"node": "Parse & Prepare Stories", "type": "main", "index": 0}]]
    },
    "Parse & Prepare Stories": {
      "main": [[{"node": "Save User Story", "type": "main", "index": 0}]]
    },
    "Save User Story": {
      "main": [[{"node": "Aggregate Results", "type": "main", "index": 0}]]
    },
    "Aggregate Results": {
      "main": [[{"node": "Respond Success", "type": "main", "index": 0}]]
    }
  }
}
```

**Changements cl√©s** :
1. ‚úÖ Suppression des n≈ìuds "Has Cadrage?", "Fetch Project Cadrage", "No Cadrage"
2. ‚úÖ Suppression de la r√©f√©rence `cadrage_id`
3. ‚úÖ Ajout de `project_id` dans le input
4. ‚úÖ R√©cup√©ration UNIQUEMENT de `stack_technique`
5. ‚úÖ Prompt Gemini simplifi√© et plus strict sur le scope
6. ‚úÖ Workflow lin√©aire : Webhook ‚Üí Keep Data ‚Üí Fetch Stack ‚Üí Prepare ‚Üí Gemini ‚Üí Parse ‚Üí Save ‚Üí Respond

### 3Ô∏è‚É£ Modification de l'Interface Symfony

#### A. Supprimer les r√©f√©rences au cadrage dans les templates

```bash
# Rechercher les r√©f√©rences
grep -r "cadrage" symfony-app/templates/
```

#### B. Modifier `ProjectController.php`

Supprimer les m√©thodes li√©es au cadrage (si elles existent).

#### C. Nettoyer `Entity/Project.php`

Le champ `project_cadrage` reste mais sa documentation change :

```php
/**
 * Cadrage technique du projet (stack, architecture)
 * Rempli manuellement ou via import, utilis√© comme contexte pour la g√©n√©ration de code
 */
#[ORM\Column(type: 'json', nullable: true)]
private ?array $projectCadrage = null;
```

### 4Ô∏è‚É£ Script de Migration Complet

```sql
-- ======================
-- MIGRATION: Suppression Agent Cadrage
-- Date: 2025-10-17
-- ======================

BEGIN;

-- 1. V√©rifications pr√©alables
DO $$
DECLARE
  cadrage_count INT;
  us_with_cadrage INT;
BEGIN
  SELECT COUNT(*) INTO cadrage_count FROM maestro.cadrages;
  SELECT COUNT(*) INTO us_with_cadrage FROM maestro.user_stories WHERE cadrage_id IS NOT NULL;

  RAISE NOTICE '=== √âTAT ACTUEL ===';
  RAISE NOTICE 'Cadrages existants: %', cadrage_count;
  RAISE NOTICE 'User Stories avec cadrage_id: %', us_with_cadrage;

  IF us_with_cadrage > 0 THEN
    RAISE WARNING 'ATTENTION: % user stories ont un cadrage_id non-null', us_with_cadrage;
  END IF;
END $$;

-- 2. Backup des donn√©es (au cas o√π)
CREATE TABLE IF NOT EXISTS maestro.cadrages_backup_20251017 AS
SELECT * FROM maestro.cadrages;

-- 3. Supprimer la colonne cadrage_id de user_stories
ALTER TABLE maestro.user_stories DROP COLUMN IF EXISTS cadrage_id CASCADE;

-- 4. Supprimer la table cadrages
DROP TABLE IF EXISTS maestro.cadrages CASCADE;

-- 5. Nettoyer les project_cadrage (optionnel)
-- D√©commenter si vous voulez repartir de z√©ro
-- UPDATE maestro.projects
-- SET project_cadrage = NULL,
--     project_cadrage_version = NULL,
--     project_cadrage_updated_at = NULL;

-- 6. V√©rification finale
DO $$
BEGIN
  RAISE NOTICE '=== MIGRATION TERMIN√âE ===';
  RAISE NOTICE 'Colonne cadrage_id supprim√©e de user_stories';
  RAISE NOTICE 'Table cadrages supprim√©e';
  RAISE NOTICE 'Backup cr√©√© dans cadrages_backup_20251017';
END $$;

COMMIT;
```

## üß™ Plan de Test

### Test 1: Cr√©er une requ√™te simple

```bash
curl -X POST https://maestro.ara-solutions.cloud/request/new \
  -d "title=Test sans cadrage" \
  -d "description=Page CGV simple" \
  -d "type=FEATURE" \
  -d "priority=MEDIUM"
```

**Attendu** :
- Agent PM analyse
- Agent US g√©n√®re des stories (sans passer par Cadrage)
- Stories cr√©√©es avec `cadrage_id = NULL`

### Test 2: V√©rifier le workflow US

```bash
curl -X POST http://n8n:5678/webhook/user-stories \
  -H "Content-Type: application/json" \
  -d '{
    "analysis_id": "...",
    "request_id": "...",
    "project_id": "...",
    "request_text": "Cr√©er une page CGV",
    "complexity": "S"
  }'
```

**Attendu** :
- R√©cup√©ration de la stack technique uniquement
- G√©n√©ration de 2-3 User Stories cibl√©es
- Pas de fonctionnalit√©s hors scope

### Test 3: V√©rifier la base de donn√©es

```sql
-- V√©rifier qu'il n'y a plus de cadrage_id
SELECT column_name
FROM information_schema.columns
WHERE table_name = 'user_stories' AND column_name = 'cadrage_id';
-- Attendu: 0 r√©sultats

-- V√©rifier que la table cadrages n'existe plus
SELECT tablename
FROM pg_tables
WHERE schemaname = 'maestro' AND tablename = 'cadrages';
-- Attendu: 0 r√©sultats
```

## üìÖ Planning d'Ex√©cution

1. **Phase 1** : Migration base de donn√©es (5 min)
2. **Phase 2** : Suppression workflow Agent Cadrage (2 min)
3. **Phase 3** : Modification Agent US Generator (10 min)
4. **Phase 4** : Modification Agent Orchestrator (10 min)
5. **Phase 5** : Tests de validation (15 min)

**Dur√©e totale estim√©e** : ~45 minutes

## ‚úÖ Checklist de Validation

- [ ] Table `cadrages` supprim√©e
- [ ] Colonne `cadrage_id` supprim√©e de `user_stories`
- [ ] Workflow Agent Cadrage supprim√© de n8n
- [ ] Workflow Agent US Generator simplifi√©
- [ ] Workflow Agent Orchestrator mis √† jour
- [ ] Test de cr√©ation de requ√™te r√©ussi
- [ ] Test de g√©n√©ration US r√©ussi
- [ ] User Stories cr√©√©es sans ambigu√Øt√© de scope
- [ ] Logs n8n propres (pas d'erreurs)
- [ ] Documentation mise √† jour

## üöÄ B√©n√©fices Attendus

‚úÖ **Simplicit√©** : Workflow lin√©aire PM ‚Üí US ‚Üí DEV
‚úÖ **Clart√©** : Scope limit√© √† la demande pr√©cise
‚úÖ **Performance** : Moins de tokens Gemini, moins de requ√™tes DB
‚úÖ **Maintenabilit√©** : Moins de code, moins de bugs
‚úÖ **Rapidit√©** : Un agent en moins = temps de traitement r√©duit

---

**Pr√™t √† ex√©cuter ? Validez ce plan avant de continuer.**
